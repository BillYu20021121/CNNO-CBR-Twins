{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import deeplift\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Conv1D, MaxPooling1D, Flatten, Dropout, Activation, Layer, Input,embeddings\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import backend as K\n",
    "from deeplift.conversion import kerasapi_conversion as kc\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeeOscillator:\n",
    "    def __init__(self, a=[1, 1, 1, 1, -1, -1, -1, -1], b=[0.6, 0.6, -0.5, 0.5, -0.6, -0.6, -0.5, 0.5], K=50, N=10):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "\n",
    "    def _initialize_tensors(self, x, N):\n",
    "        shape = tf.shape(x)\n",
    "        rank = tf.rank(x)\n",
    "\n",
    "        if rank == 2:\n",
    "            x = tf.expand_dims(tf.expand_dims(x, axis=1), axis=1)\n",
    "            shape = tf.shape(x)\n",
    "        elif rank == 4 and shape[1] > 1:\n",
    "            x = tf.transpose(x, [0, 2, 3, 1])\n",
    "            shape = tf.shape(x)\n",
    "\n",
    "        init_shape = tf.concat([[N], shape], axis=0)\n",
    "        u = tf.zeros(init_shape, dtype=tf.float32)\n",
    "        v = tf.zeros(init_shape, dtype=tf.float32)\n",
    "        z = tf.zeros(init_shape, dtype=tf.float32)\n",
    "        u = tf.tensor_scatter_nd_update(u, [[0]], [u[0] + 0.2])\n",
    "        z = tf.tensor_scatter_nd_update(z, [[0]], [z[0] + 0.2])\n",
    "\n",
    "        return u, v, z, x\n",
    "\n",
    "    def Tanh(self, x):\n",
    "        N = np.random.randint(1, self.N + 1)\n",
    "        u, v, z, x = self._initialize_tensors(x, N)\n",
    "\n",
    "        for t in range(N - 1):\n",
    "            u = tf.tensor_scatter_nd_update(u, [[t + 1]], [\n",
    "                tf.math.tanh(self.a[0] * u[t] - self.a[1] * v[t] + self.a[2] * z[t] + self.a[3] * x)])\n",
    "            v = tf.tensor_scatter_nd_update(v, [[t + 1]], [\n",
    "                tf.math.tanh(self.a[6] * z[t] - self.a[4] * u[t] - self.a[5] * v[t] + self.a[7] * x)])\n",
    "            w = tf.math.tanh(x)\n",
    "            z = tf.tensor_scatter_nd_update(z, [[t + 1]], [(v[t + 1] - u[t + 1]) * tf.math.exp(-self.K * tf.math.pow(x, 2)) + w])\n",
    "\n",
    "        if tf.rank(x) == 4 and tf.shape(x)[1] > 1:\n",
    "            z = tf.transpose(z[-1], [0, 3, 1, 2])\n",
    "\n",
    "        return z[-1]\n",
    "\n",
    "    def Sigmoid(self, x):\n",
    "        N = np.random.randint(1, self.N + 1)\n",
    "        u, v, z, x = self._initialize_tensors(x, N)\n",
    "\n",
    "        for t in range(N - 1):\n",
    "            u = tf.tensor_scatter_nd_update(u, [[t + 1]], [\n",
    "                tf.math.sigmoid(self.b[0] * u[t] - self.b[1] * v[t] + self.b[2] * z[t] + self.b[3] * x)])\n",
    "            v = tf.tensor_scatter_nd_update(v, [[t + 1]], [\n",
    "                tf.math.sigmoid(self.b[6] * z[t] - self.b[4] * u[t] - self.b[5] * v[t] + self.b[7] * x)])\n",
    "            w = tf.math.sigmoid(x)\n",
    "            z = tf.tensor_scatter_nd_update(z, [[t + 1]], [(v[t + 1] - u[t + 1]) * tf.math.exp(-self.K * tf.math.pow(x, 2)) + w])\n",
    "\n",
    "        if tf.rank(x) == 4 and tf.shape(x)[1] > 1:\n",
    "            z = tf.transpose(z[-1], [0, 3, 1, 2])\n",
    "\n",
    "        return z[-1]\n",
    "\n",
    "    def ReLU(self, x):\n",
    "        N = np.random.randint(1, self.N + 1)\n",
    "        u, v, z, x = self._initialize_tensors(x, N)\n",
    "\n",
    "        for t in range(N - 1):\n",
    "            u = tf.tensor_scatter_nd_update(u, [[t + 1]], [\n",
    "                tf.nn.relu(self.a[0] * u[t] - self.a[1] * v[t] + self.a[2] * z[t] + self.a[3] * x)])\n",
    "            v = tf.tensor_scatter_nd_update(v, [[t + 1]], [\n",
    "                tf.nn.relu(self.a[6] * z[t] - self.a[4] * u[t] - self.a[5] * v[t] + self.a[7] * x)])\n",
    "            w = tf.nn.relu(x)\n",
    "            z = tf.tensor_scatter_nd_update(z, [[t + 1]], [(v[t + 1] - u[t + 1]) * tf.math.exp(-self.K * tf.math.pow(x, 2)) + w])\n",
    "\n",
    "        if tf.rank(x) == 4 and tf.shape(x)[1] > 1:\n",
    "            z = tf.transpose(z[-1], [0, 3, 1, 2])\n",
    "\n",
    "        return z[-1]\n",
    "\n",
    "    def LeakyReLU(self, x, alpha=0.1):\n",
    "        N = np.random.randint(1, self.N + 1)\n",
    "        u, v, z, x = self._initialize_tensors(x, N)\n",
    "\n",
    "        for t in range(N - 1):\n",
    "            u = tf.tensor_scatter_nd_update(u, [[t + 1]], [\n",
    "                tf.nn.leaky_relu(self.a[0] * u[t] - self.a[1] * v[t] + self.a[2] * z[t] + self.a[3] * x, alpha=alpha)])\n",
    "            v = tf.tensor_scatter_nd_update(v, [[t + 1]], [\n",
    "                tf.nn.leaky_relu(self.a[6] * z[t] - self.a[4] * u[t] - self.a[5] * v[t] + self.a[7] * x, alpha=alpha)])\n",
    "            w = tf.nn.leaky_relu(x, alpha=alpha)\n",
    "            z = tf.tensor_scatter_nd_update(z, [[t + 1]], [(v[t + 1] - u[t + 1]) * tf.math.exp(-self.K * tf.math.pow(x, 2)) + w])\n",
    "\n",
    "        if tf.rank(x) == 4 and tf.shape(x)[1] > 1:\n",
    "            z = tf.transpose(z[-1], [0, 3, 1, 2])\n",
    "\n",
    "        return z[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义激活层\n",
    "class LeeOscillatorTanhLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LeeOscillatorTanhLayer, self).__init__(**kwargs)\n",
    "        self.oscillator = LeeOscillator()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.oscillator.Tanh(inputs)\n",
    "\n",
    "class LeeOscillatorSigmoidLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LeeOscillatorSigmoidLayer, self).__init__(**kwargs)\n",
    "        self.oscillator = LeeOscillator()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.oscillator.Sigmoid(inputs)\n",
    "\n",
    "class LeeOscillatorReLULayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LeeOscillatorReLULayer, self).__init__(**kwargs)\n",
    "        self.oscillator = LeeOscillator()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.oscillator.ReLU(inputs)\n",
    "\n",
    "class LeeOscillatorLeakyReLULayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LeeOscillatorLeakyReLULayer, self).__init__(**kwargs)\n",
    "        self.oscillator = LeeOscillator()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.oscillator.LeakyReLU(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {'LeeOscillatorReLULayer': LeeOscillatorReLULayer}\n",
    "model = load_model(\"NN.h5\", custom_objects=custom_objects)\n",
    "\n",
    "new_true_model = Sequential()\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, keras.layers.Embedding):\n",
    "        # 替换Embedding层\n",
    "        new_true_model.add(Dense(units=layer.output_dim, activation='relu'))\n",
    "    else:\n",
    "        new_true_model.add(layer)\n",
    "\n",
    "# 保存修改后的模型\n",
    "new_true_model.save(\"modified_NN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X_train = np.load(\"X_train.npy\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "\n",
    "oh_y_train = np.load(\"oh_y_train.npy\")\n",
    "oh_y_test = np.load(\"oh_y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改此处1：只读取前1000个数据样本\n",
    "X_train = X_train[:1000]\n",
    "X_test = X_test[:1000]\n",
    "y_train = y_train[:1000]\n",
    "y_test = y_test[:1000]\n",
    "oh_y_train = oh_y_train[:1000]\n",
    "oh_y_test = oh_y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For indexing\n",
    "nn_preds_test = model.predict_classes(X_test)\n",
    "nn_preds_train = model.predict_classes(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Manually construct a new fake model without the Embedding layer\n",
    "inputs = Input(shape=(500, 128))  # Input shape should match the output shape of the Embedding layer\n",
    "x = Conv1D(32, 5, padding='same', name='conv1')(inputs)\n",
    "x = Activation(\"relu\", name='activation1')(x)\n",
    "x = MaxPooling1D(pool_size=2, name='maxpool1')(x)\n",
    "x = Conv1D(64, 3, padding='same', name='conv2')(x)\n",
    "x = Activation(\"relu\", name='activation2')(x)\n",
    "x = MaxPooling1D(pool_size=2, name='maxpool2')(x)\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(128, name='dense1')(x)\n",
    "x = Activation(\"relu\", name='activation3')(x)\n",
    "x = Dropout(0.2, name='dropout1')(x)\n",
    "x = Dense(50, name='dense2')(x)\n",
    "x = Activation(\"relu\", name='activation4')(x)\n",
    "x = Dropout(0.2, name='dropout2')(x)\n",
    "outputs = Dense(46, name='output')(x)\n",
    "outputs = Activation(\"softmax\", name='activation5')(outputs)\n",
    "\n",
    "# Create a new model without the Embedding layer\n",
    "fake_model = Model(inputs, outputs)\n",
    "\n",
    "# Transfer the weights from the trained model to the new model\n",
    "fake_model.get_layer(name='conv1').set_weights(model.get_layer(name='conv1d_1').get_weights())\n",
    "fake_model.get_layer(name='conv2').set_weights(model.get_layer(name='conv1d_2').get_weights())\n",
    "fake_model.get_layer(name='dense1').set_weights(model.get_layer(name='dense_1').get_weights())\n",
    "fake_model.get_layer(name='dense2').set_weights(model.get_layer(name='dense_2').get_weights())\n",
    "fake_model.get_layer(name='output').set_weights(model.get_layer(name='dense_3').get_weights())\n",
    "\n",
    "# Save the new model to file\n",
    "fake_model.save('fake_model_NN_no_embedding.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_6\n",
      "conv1\n",
      "activation1\n",
      "maxpool1\n",
      "conv2\n",
      "activation2\n",
      "maxpool2\n",
      "flatten\n",
      "dense1\n",
      "activation3\n",
      "dropout1\n",
      "dense2\n",
      "activation4\n",
      "dropout2\n",
      "output\n",
      "activation5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bill\\.conda\\envs\\python3.6\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# Load the model to access the weights\n",
    "model = load_model('fake_model_NN_no_embedding.h5')\n",
    "\n",
    "# Print the names of the layers in the trained model\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from deeplift.conversion import kerasapi_conversion as kc\n",
    "\n",
    "# Assuming you have pre-computed embeddings for X_train and X_test\n",
    "# For simplicity, here we generate random embeddings. Replace this with actual embeddings.\n",
    "precomputed_embeddings_train = np.random.rand(X_train.shape[0], 500, 128)\n",
    "precomputed_embeddings_test = np.random.rand(X_test.shape[0], 500, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bill\\.conda\\envs\\python3.6\\lib\\site-packages\\deeplift\\conversion\\kerasapi_conversion.py:359: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  str_data = h5py.File(h5_file).attrs[\"model_config\"]\n",
      "c:\\Users\\Bill\\.conda\\envs\\python3.6\\lib\\site-packages\\deeplift\\conversion\\kerasapi_conversion.py:366: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  model_weights = h5py.File(h5_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonlinear_mxts_mode is set to: DeepLIFT_GenomicsDefault\n",
      "For layer activation1_0 the preceding linear layer is conv1_0 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "For layer activation2_0 the preceding linear layer is conv2_0 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "For layer activation3_0 the preceding linear layer is dense1_0 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "For layer activation4_0 the preceding linear layer is dense2_0 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "Heads-up: I assume softmax is the output layer, not an intermediate one; if it's an intermediate layer, please let me know and I will prioritise that use-case\n",
      "For layer activation5_0 the preceding linear layer is output_0 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n",
      "No reference provided - using zeros\n",
      "Done 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the new model using DeepLIFT\n",
    "deeplift_model = deeplift.conversion.kerasapi_conversion.convert_model_from_saved_files(\n",
    "    \"fake_model_NN_no_embedding.h5\",\n",
    "    nonlinear_mxts_mode=deeplift.layers.NonlinearMxtsMode.DeepLIFT_GenomicsDefault)\n",
    "\n",
    "# Define the layer to propagate contribution scores\n",
    "find_scores_layer_name = 'dense1_0'\n",
    "pre_activation_target_layer_name = 'output_0'\n",
    "\n",
    "# Get the target contribution function\n",
    "deeplift_contribs_func = deeplift_model.get_target_contribs_func(\n",
    "    find_scores_layer_name=find_scores_layer_name,\n",
    "    pre_activation_target_layer_name=pre_activation_target_layer_name)\n",
    "\n",
    "# Iterate scores for each output neuron one at a time\n",
    "for i in range(model.get_weights()[-1].shape[0]):\n",
    "    train = np.array(deeplift_contribs_func(task_idx=i,\n",
    "                                            input_data_list=[precomputed_embeddings_train],\n",
    "                                            batch_size=10,\n",
    "                                            progress_update=1000))\n",
    "\n",
    "    test = np.array(deeplift_contribs_func(task_idx=i,\n",
    "                                           input_data_list=[precomputed_embeddings_test],\n",
    "                                           batch_size=10,\n",
    "                                           progress_update=1000))\n",
    "\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    train = np.expand_dims(train, 1)\n",
    "    test = np.expand_dims(test, 1)\n",
    "\n",
    "    if i == 0:\n",
    "        X_train_deeplift = deepcopy(train)\n",
    "        X_test_deeplift = deepcopy(test)\n",
    "    else:\n",
    "        X_train_deeplift = np.append(X_train_deeplift, train, axis=1)\n",
    "        X_test_deeplift = np.append(X_test_deeplift, test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = deepcopy(X_train_deeplift)\n",
    "test = deepcopy(X_test_deeplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_deeplift = list()\n",
    "X_test_deeplift = list()\n",
    "\n",
    "for i in range(len(nn_preds_train)):\n",
    "    index = nn_preds_train[i]\n",
    "    X_train_deeplift.append(train[i][index])\n",
    "\n",
    "for i in range(len(nn_preds_test)):\n",
    "    index = nn_preds_test[i]\n",
    "    X_test_deeplift.append(test[i][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_deeplift = np.array(X_train_deeplift)\n",
    "X_test_deeplift = np.array(X_test_deeplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (1000, 128)\n",
      "Testing: (1000, 128)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training:\", X_train_deeplift.shape)\n",
    "print(\"Testing:\", X_test_deeplift.shape)\n",
    "\n",
    "np.save(\"new_X_train_deeplift\", X_train_deeplift)\n",
    "np.save(\"new_X_test_deeplift\", X_test_deeplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NB: MAKE SURE CORRECT MODEL\n",
    "custom_objects = {'LeeOscillatorReLULayer': LeeOscillatorReLULayer}\n",
    "model = load_model(\"modified_NN.h5\", custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(model, model_inputs, print_shape_only=False, layer_name=None):\n",
    "    activations = []\n",
    "    inp = model.input\n",
    "\n",
    "    model_multi_inputs_cond = True\n",
    "    if not isinstance(inp, list):\n",
    "        inp = [inp]\n",
    "        model_multi_inputs_cond = False\n",
    "\n",
    "    outputs = [layer.output for layer in model.layers if\n",
    "               layer.name == layer_name or layer_name is None]\n",
    "\n",
    "    funcs = [K.function(inp + [K.learning_phase()], [out]) for out in outputs]\n",
    "\n",
    "    if model_multi_inputs_cond:\n",
    "        list_inputs = []\n",
    "        list_inputs.extend(model_inputs)\n",
    "        list_inputs.append(0.)\n",
    "    else:\n",
    "        list_inputs = [model_inputs, 0.]\n",
    "\n",
    "    layer_outputs = [func(list_inputs)[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "        if print_shape_only:\n",
    "            print(layer_activations.shape)\n",
    "        else:\n",
    "            print(layer_activations)\n",
    "\n",
    "    return activations\n",
    "\n",
    "X_train_act = list()\n",
    "X_test_act = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(1000, 500, 128)\n",
      "(1000, 500, 128)\n",
      "(1000, 500, 32)\n",
      "(1000, 500, 32)\n",
      "(1000, 250, 32)\n",
      "(1000, 250, 64)\n",
      "(1000, 250, 64)\n",
      "(1000, 125, 64)\n",
      "(1000, 8000)\n",
      "(1000, 128)\n",
      "(1000, 128)\n",
      "(1000, 128)\n",
      "(1000, 50)\n",
      "(1000, 50)\n",
      "(1000, 50)\n",
      "(1000, 46)\n",
      "(1000, 46)\n",
      "0\n",
      "(1000, 500, 128)\n",
      "(1000, 500, 128)\n",
      "(1000, 500, 32)\n",
      "(1000, 500, 32)\n",
      "(1000, 250, 32)\n",
      "(1000, 250, 64)\n",
      "(1000, 250, 64)\n",
      "(1000, 125, 64)\n",
      "(1000, 8000)\n",
      "(1000, 128)\n",
      "(1000, 128)\n",
      "(1000, 128)\n",
      "(1000, 50)\n",
      "(1000, 50)\n",
      "(1000, 50)\n",
      "(1000, 46)\n",
      "(1000, 46)\n"
     ]
    }
   ],
   "source": [
    "# 修改此处，根据修改1处的数量修改for i in range(0, x, 1000): 里的x\n",
    "for i in range(0, 1000, 1000):\n",
    "    print(i)\n",
    "    start = i\n",
    "    end = i + 1000\n",
    "\n",
    "    X_train_act_seg = get_activations(model, X_train[start: end],print_shape_only=True)[-8]\n",
    "    X_train_act.append(X_train_act_seg)\n",
    "\n",
    "# 修改此处，根据修改1处的数量修改for i in range(0, x, 1000): 里的x\n",
    "for i in range(0, 1000, 1000):\n",
    "    print(i)\n",
    "    start = i\n",
    "    end = i + 1000\n",
    "\n",
    "    X_test_act_seg = get_activations(model, X_test[start: end],print_shape_only=True)[-8]\n",
    "    X_test_act.append(X_test_act_seg)\n",
    "\n",
    "X_train_act_new = list()\n",
    "X_test_act_new = list()\n",
    "\n",
    "for group in X_train_act:\n",
    "    for i in range(len(group)):\n",
    "        X_train_act_new.append(group[i])\n",
    "\n",
    "for group in X_test_act:\n",
    "    for i in range(len(group)):\n",
    "        X_test_act_new.append(group[i])\n",
    "\n",
    "X_train_act = np.array(X_train_act_new)\n",
    "X_test_act = np.array(X_test_act_new)\n",
    "\n",
    "np.save(\"X_train_act\", X_train_act)\n",
    "np.save(\"X_test_act\", X_test_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import deeplift\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Conv1D, MaxPooling1D, Flatten, Dropout, Activation, Layer, Input,embeddings\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import backend as K\n",
    "from deeplift.conversion import kerasapi_conversion as kc\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# For keras dependencise\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import backend as K\n",
    "\n",
    "# For LRP Visuals\n",
    "from deepexplain.tensorflow import DeepExplain\n",
    "from keras.models import Model\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a value of k for the dataset\n",
    "k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {'LeeOscillatorReLULayer': LeeOscillatorReLULayer}\n",
    "model = load_model(\"modified_NN.h5\", custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X_train = np.load(\"X_train.npy\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "\n",
    "# 修改此处1：只读取前1000个数据样本\n",
    "X_train = X_train[:1000]\n",
    "X_test = X_test[:1000]\n",
    "y_train = y_train[:1000]\n",
    "y_test = y_test[:1000]\n",
    "\n",
    "\n",
    "# Load the feature activations\n",
    "X_train_act = np.load(\"X_train_act.npy\")\n",
    "X_test_act = np.load(\"X_test_act.npy\")\n",
    "# 将三维数据重塑为二维\n",
    "X_train_act = X_train_act.reshape(X_train_act.shape[0], -1)\n",
    "X_test_act = X_test_act.reshape(X_test_act.shape[0], -1)\n",
    "\n",
    "\n",
    "# Load DeepLIFT contributions\n",
    "X_train_cont = np.load(\"new_X_train_deeplift.npy\")\n",
    "X_test_cont = np.load(\"new_X_test_deeplift.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1000, 500)\n",
      "X_test shape: (1000, 500)\n"
     ]
    }
   ],
   "source": [
    "nn_pred = model.predict_classes(X_test)\n",
    "# 确定数据形状\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_knn shape: (1000, 500)\n",
      "X_test_knn shape: (1000, 500)\n"
     ]
    }
   ],
   "source": [
    "# 重新定义数据形状以适应KNN分类器\n",
    "X_train_knn = X_train.reshape(X_train.shape[0], 50*10)\n",
    "X_test_knn = X_test.reshape(X_test.shape[0], 50*10)\n",
    "print(\"X_train_knn shape:\", X_train_knn.shape)\n",
    "print(\"X_test_knn shape:\", X_test_knn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-DeepLIFT-KNN: (1000, 128)\n",
      "Activations: (1000, 128)\n",
      "Training: (1000, 500)\n",
      "Training k-NN: (1000, 500)\n",
      "y_test: (1000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"C-DeepLIFT-KNN:\", X_train_cont.shape)\n",
    "print(\"Activations:\", X_train_act.shape)\n",
    "print(\"Training:\", X_train.shape)\n",
    "print(\"Training k-NN:\", X_train_knn.shape)\n",
    "print(\"y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_cont = np.sum(X_train_cont, axis=2)\n",
    "#print(\"C-DeepLIFT-KNN:\", X_train_cont.shape)\n",
    "#X_test_cont = np.sum(X_test_cont, axis=2)\n",
    "#print(\"C-DeepLIFT-KNN:\", X_test_cont.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "k-NN*\n",
      "==================================================\n",
      "Accuracy: 0.627\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0 17  1 ...  0  0  0]\n",
      " [ 0  1  1 ...  0  0  0]\n",
      " ...\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      " \n",
      "Agreement 0.741\n",
      "==================================================\n",
      "C-DeepLIFT\n",
      "==================================================\n",
      "Accuracy: 0.636\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0 28  0 ...  0  0  0]\n",
      " [ 0  4  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      " \n",
      "Agreement 0.857\n"
     ]
    }
   ],
   "source": [
    "techniques = [\n",
    "    [\"k-NN*\", X_train_act, X_test_act],\n",
    "    [\"C-DeepLIFT\", X_train_cont, X_test_cont]\n",
    "]\n",
    "\n",
    "\n",
    "for item in techniques:\n",
    "    technique = item[0]\n",
    "    train = item[1]\n",
    "    test = item[2]\n",
    "\n",
    "    print(\"==================================================\")\n",
    "    print(technique)\n",
    "    print(\"==================================================\")\n",
    "\n",
    "    kNN = KNeighborsClassifier(n_neighbors=9, algorithm=\"brute\")\n",
    "    kNN.fit(train, y_train)\n",
    "\n",
    "    knn_predictions_test = kNN.predict(test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, knn_predictions_test))\n",
    "    print(confusion_matrix(y_test, knn_predictions_test, labels=None, sample_weight=None))\n",
    "    print(\" \")\n",
    "\n",
    "    # What's the % that's different?\n",
    "    correct = 0\n",
    "    for i in range(len(nn_pred)):\n",
    "        if knn_predictions_test[i] == nn_pred[i]:\n",
    "            correct += 1\n",
    "    print(\"Agreement\", correct / len(nn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "k-NN*\n",
      "==================================================\n",
      "Accuracy: 0.627\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0 17  1 ...  0  0  0]\n",
      " [ 0  1  1 ...  0  0  0]\n",
      " ...\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      " \n",
      "Agreement 0.741\n",
      "==================================================\n",
      "C-DeepLIFT\n",
      "==================================================\n",
      "Accuracy: 0.636\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0 28  0 ...  0  0  0]\n",
      " [ 0  4  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      " \n",
      "Agreement 0.857\n"
     ]
    }
   ],
   "source": [
    "techniques = [\n",
    "    [\"k-NN*\", X_train_act, X_test_act],\n",
    "    [\"C-DeepLIFT\", X_train_cont, X_test_cont]\n",
    "]\n",
    "\n",
    "\n",
    "for item in techniques:\n",
    "    technique = item[0]\n",
    "    train = item[1]\n",
    "    test = item[2]\n",
    "\n",
    "    print(\"==================================================\")\n",
    "    print(technique)\n",
    "    print(\"==================================================\")\n",
    "\n",
    "    kNN = KNeighborsClassifier(n_neighbors=9, algorithm=\"brute\")\n",
    "    kNN.fit(train, y_train)\n",
    "\n",
    "    knn_predictions_test = kNN.predict(test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, knn_predictions_test))\n",
    "    print(confusion_matrix(y_test, knn_predictions_test, labels=None, sample_weight=None))\n",
    "    print(\" \")\n",
    "\n",
    "    # What's the % that's different?\n",
    "    correct = 0\n",
    "    for i in range(len(nn_pred)):\n",
    "        if knn_predictions_test[i] == nn_pred[i]:\n",
    "            correct += 1\n",
    "    print(\"Agreement\", correct / len(nn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_idx = list()\n",
    "for i in range(len(X_train)):\n",
    "    if y_train[i] != model.predict_classes(np.array([X_train[i]]))[0]:\n",
    "        del_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify shape for next loop\n",
    "y_train = np.array([y_train]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_modify = [X_train, y_train, X_train_act,\n",
    "             X_train_cont]\n",
    "\n",
    "modified = list()\n",
    "for i in range(len(to_modify)):\n",
    "    matrix = deepcopy(to_modify[i].tolist())\n",
    "    for index in sorted(del_idx, reverse=True):\n",
    "        del matrix[index]\n",
    "    modified.append(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['X_train_del', 'y_train_del', 'X_train_act_del',\n",
    "         'X_train_cont_del']\n",
    "\n",
    "for i in range(len(names)):\n",
    "    matrix = np.array(modified[i])\n",
    "    name = names[i]\n",
    "    # for y_train\n",
    "    if i == 1:\n",
    "        matrix = matrix.T[0]\n",
    "    np.save(name, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"X_train_del.npy\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_train = np.load(\"y_train_del.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "\n",
    "# 修改此处1：只读取前1000个数据样本\n",
    "y_test = y_test[:1000]\n",
    "\n",
    "X_train_act = np.load(\"X_train_act_del.npy\")\n",
    "X_train_cont = np.load(\"X_train_cont_del.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred = model.predict_classes(X_test)\n",
    "# 修改此处1：只读取前1000个数据样本\n",
    "nn_pred = nn_pred[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-DeepLIFT-KNN: (698, 128)\n",
      "Activations: (698, 128)\n",
      "Training: (698, 500)\n",
      "Training k-NN: (1000, 500)\n",
      "y_test: (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"C-DeepLIFT-KNN:\", X_train_cont.shape)\n",
    "print(\"Activations:\", X_train_act.shape)\n",
    "print(\"Training:\", X_train.shape)\n",
    "print(\"Training k-NN:\", X_train_knn.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "k-NN*\n",
      "==================================================\n",
      "Accuracy: 0.63\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0 18  0 ...  0  0  0]\n",
      " [ 0  3  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  1  0 ...  0  0  0]]\n",
      " \n",
      "Agreement 0.84\n",
      "==================================================\n",
      "C-DeepLIFT\n",
      "==================================================\n",
      "Accuracy: 0.644\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0 25  0 ...  0  0  0]\n",
      " [ 0  2  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      " \n",
      "Agreement 0.904\n"
     ]
    }
   ],
   "source": [
    "techniques = [\n",
    "    [\"k-NN*\", X_train_act, X_test_act],\n",
    "    [\"C-DeepLIFT\", X_train_cont, X_test_cont]\n",
    "]\n",
    "\n",
    "for item in techniques:\n",
    "    technique = item[0]\n",
    "    train = item[1]\n",
    "    test = item[2]\n",
    "\n",
    "    print(\"==================================================\")\n",
    "    print(technique)\n",
    "    print(\"==================================================\")\n",
    "\n",
    "    kNN = KNeighborsClassifier(n_neighbors=9, algorithm=\"brute\")\n",
    "    kNN.fit(train, y_train)\n",
    "\n",
    "    knn_predictions_test = kNN.predict(test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, knn_predictions_test))\n",
    "    print(confusion_matrix(y_test, knn_predictions_test, labels=None, sample_weight=None))\n",
    "    print(\" \")\n",
    "\n",
    "    # What's the % that's different?\n",
    "    correct = 0\n",
    "    for i in range(len(nn_pred)):\n",
    "        if knn_predictions_test[i] == nn_pred[i]:\n",
    "            correct += 1\n",
    "    print(\"Agreement\", correct / len(nn_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
